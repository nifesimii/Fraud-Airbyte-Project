executor: "KubernetesExecutor"
cleanUpPods: false

images:
  airflow:
    repository: my-dags
    tag: "20260131164649"
    pullPolicy: IfNotPresent

scheduler:
  replicas: 1

triggerer:
  replicas: 1

workers:
  replicas: 0

redis:
  enabled: false

postgresql:
  enabled: true
  image:
    registry: docker.io
    repository: bitnamilegacy/postgresql
    tag: "14.10.0"
    pullPolicy: IfNotPresent
  auth:
    enablePostgresUser: true
    postgresPassword: postgres
  primary:
    persistence:
      enabled: false

# ============================================================================
# PERSISTENT LOGS CONFIGURATION
# ============================================================================
logs:
  persistence:
    enabled: false
    existingClaim: airflow-logs

# ============================================================================
# DAG CONFIGURATION (Git-Sync)
# ============================================================================
dags:
  persistence:
    enabled: false
  gitSync:
    enabled: true
    repo: https://github.com/nifesimii/Fraud-Airbyte-Project.git
    branch: main
    rev: HEAD
    depth: 1
    maxFailures: 0
    subPath: "airflow/dags"
    wait: 60
    containerName: git-sync
    uid:
      65533
      # Add this to use simpler sync method:
    extraVolumeMounts:
      - name: dags
        mountPath: /git

# ============================================================================
# AIRFLOW CONFIGURATION
# ============================================================================
config:
  core:
    load_examples: "False"
  webserver:
    expose_config: "True"
  kubernetes:
    delete_worker_pods: "False"
    delete_worker_pods_on_failure: "False"
  logging:
    base_log_folder: "/opt/airflow/logs"
    remote_logging: "False"
    logging_level: "INFO"
    fab_logging_level: "WARNING"
    log_filename_template: "{{`{{ ti.dag_id }}/{{ ti.task_id }}/{{ ts }}/{{ try_number }}.log`}}"
    log_processor_filename_template: "{{`{{ filename }}.log`}}"
    dag_processor_manager_log_location: "/opt/airflow/logs/dag_processor_manager/dag_processor_manager.log"
    # ✅ ADD THESE LINES:
    task_log_reader: "file.task" # Read from filesystem, not worker pods
    logging_config_class: "" # Use default file-based logging

# ============================================================================
# ENVIRONMENT VARIABLES
# ============================================================================
env:
  - name: AIRFLOW__CORE__DAGS_FOLDER
    value: "/opt/airflow/dags"
  - name: AIRFLOW__LOGGING__BASE_LOG_FOLDER
    value: "/opt/airflow/logs"
  # ✅ ADD: Force file-based log reading
  - name: AIRFLOW__LOGGING__TASK_LOG_READER
    value: "file.task"
